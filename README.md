# Coffee is Great â˜•

A data pipeline project that uses **Apache Spark (Java)** to read data from a CSV file and load it into a **containerized PostgreSQL** database. After the data is loaded, a **Flask REST API** is built to interact with the database.

---

## ğŸš€ Project Overview

This project automates the process of:
1. Reading structured data from a CSV using Apache Spark.
2. Uploading and transforming it into a PostgreSQL database container.
3. Serving the data through a lightweight Flask REST API.

---

## ğŸ§± Tech Stack

- **Apache Spark (Java)** â€“ data processing
- **PostgreSQL** â€“ containerized relational database
- **Flask (Python)** â€“ RESTful API service
- **Docker** â€“ containerization of the PostgreSQL service

---

## ğŸ“ Project Structure

coffee-is-great/ 
â”œâ”€â”€ sql/ # SQL script and data model
â”œâ”€â”€ src/main/java/com/coffeeIsGreat # Apache Spark job (Java code) 
â”œâ”€â”€ api/ # Flask REST API 
â”œâ”€â”€ data/ # Input CSV files 
â”œâ”€â”€ dockerfile # PostgreSQL container configuration 
â”œâ”€â”€ pom.xml # Maven dependencies
â”œâ”€â”€ README.md #This file
â”œâ”€â”€ run.py #Flask API main file

---

ğŸ§ª API Usage
Once the API is running locally, you can access the following endpoints:
`GET /healthcheck`
Check if the API is running properly.

`GET /city`
Returns a list of cities available in the database.

`GET /products`
Returns a list of coffee products stored in the database.

---

ğŸ—„ SQL Data Model
Check the /sql directory for the SQL schema and table definitions used by the PostgreSQL database.

---

ğŸ“« Author
Carlos Lopez
ğŸ“§ carloslopez.cl265@gmail.com

