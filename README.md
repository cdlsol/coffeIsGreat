# Coffee is Great â˜•

A data pipeline project that uses **Apache Spark (Java)** to read data from a CSV file and load it into a **containerized PostgreSQL** database. After the data is loaded, a **Flask REST API** is built to interact with the database.

---

## ğŸš€ Project Overview

This project automates the process of:
1. Reading structured data from a CSV using Apache Spark.
2. Uploading and transforming it into a PostgreSQL database container.
3. Serving the data through a lightweight Flask REST API.

---

## ğŸ§± Tech Stack

- **Apache Spark (Java)** â€“ data processing
- **PostgreSQL** â€“ containerized relational database
- **Flask (Python)** â€“ RESTful API service
- **Docker** â€“ containerization of the PostgreSQL service

---

```
coffee-is-great/ 
â”œâ”€â”€ ğŸ“‚ sql/ # SQL scripts and data model 
â”œâ”€â”€ ğŸ“‚ src/main/java/com/coffeeIsGreat/ # Apache Spark job (Java code) 
â”œâ”€â”€ ğŸ“‚ api/ # Flask REST API 
â”œâ”€â”€ ğŸ“‚ data/ # Input CSV files 
â”œâ”€â”€ ğŸ³ dockerfile # PostgreSQL container configuration 
â”œâ”€â”€ ğŸ“„ pom.xml # Maven dependencies for Spark 
â”œâ”€â”€ ğŸ“„ run.py # Entry point for Flask API 
â”œâ”€â”€ ğŸ“„ README.md # Project documentation (this file)
```

---

ğŸ§ª API Usage
Once the API is running locally, you can access the following endpoints:

`GET /healthcheck`
Check if the API is running properly.

`GET /city`
Returns a list of cities available in the database.

`GET /products`
Returns a list of coffee products stored in the database.

---

ğŸ—„ SQL Data Model
Check the /sql directory for the SQL schema and table definitions used by the PostgreSQL database.

---

ğŸ“« Author
Carlos Lopez
ğŸ“§ carloslopez.cl265@gmail.com

